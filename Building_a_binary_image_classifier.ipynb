{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "* numpy - package for scientific computing with Python\n",
    "* matplotlib.pyplot - plotting framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras models\n",
    "* Sequential - basic keras model composed of a linear stack of layers.\n",
    "* model_from_json - Loads a saved model from a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras Layers\n",
    "* Conv2D- 2D convolution layer\n",
    "* MaxPooling2D - Max pooling operation for spatial data.\n",
    "* Flatten - Flattens the input. Does not affect the batch size.\n",
    "* Dense - regular densely-connected NN layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessing packages\n",
    "* image - image preprocessing package\n",
    "* ImageDataGenerator - Generate batches of tensor image data with real-time data augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the classifier model\n",
    "* Build a CNN.CNN has mostly four fucntions:\n",
    "    * Convolution: Add the first layer which is a convolutional layer. Set the number of filters as 32, the shape of each filter as 3x3 and the input shape and the type of image as 50,50,3 i.e. the input is of a 50x50 RGB image and the activation function as relu.\n",
    "    * Pooling: Add a pooling layer to reduce the total number of nodes for the upcoming layers. It takes a 2x2 matrix thus giving minimum pixel loss and a precise region where the features are located.\n",
    "    * Flatten : Flattens the pooled images.\n",
    "    * Dense : add a fully connected layer to feed the images to the output layer. Set the number of nodes as 256, as its a common practice to use a power of 2 and a rectifier function asthe activation function, relu.\n",
    "\n",
    "* Define the output layer. Set number of units to 1 as this is a binary classifier and sigmoid as the activation function\n",
    "* Compile the model. Set adam as the optimizer and binary_crossentropy as the loss fucntion, as this is a binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), input_shape = (50, 50, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 256, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the CNN to the images\n",
    "* Improve the dataset using the ImageDataGenerator method which generate batches of tensor image data with real-time data augmentation. \n",
    "    * rescale: rescaling factor. If None or 0, no rescaling is applied, otherwise the data is multiplied by the value provided.\n",
    "    * shear_range: Shear Intensity\n",
    "    * zoom_range: Range for random zoom.\n",
    "    * horizontal_flip: Randomly flip inputs horizontally if true.\n",
    "* Define the training and test datasets using the flow_from_directory which takes the path to a directory, and generates batches of augmented/normalized data.\n",
    "    * directory: path to the target directory. It should contain one subdirectory per class.\n",
    "    * target_size: The dimensions to which all images found will be resized.\n",
    "    * class_mode: one of \"categorical\", \"binary\", \"sparse\", \"input\" or None. Determines the type of label arrays that are returned\n",
    "    * batch_size: size of the batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "target_size = (50, 50),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "target_size = (50, 50),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset\n",
    "* Print a preprocessed image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = training_set.next()\n",
    "for i in range(0,1):\n",
    "    random_image = x[i]\n",
    "    plt.imshow(random_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an earlystopping callback\n",
    "* Import EarlyStopping - method to stop training when a monitored quantity has stopped improving.\n",
    "* Define a callback.Set monitor as val_acc, patience as 5 and mode as max so that if val_acc does not improve over 5 epochs, terminate the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# acc_callback = [EarlyStopping(monitor='val_acc', patience=5, mode='max')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "* Invoke the fit_generator to fits the model on data generated batch-by-batch by a Python generator.\n",
    "    * steps_per_epochâ€™ holds the number of training images, i.e 8000\n",
    "    * A single epoch is a single step in training a neural network,set it at 25.\n",
    "    * callbacks: List of callbacks to apply during training.\n",
    "    * validation_data: test data\n",
    "    * validation_steps: Total number of steps (batches of samples) to yield from  validation_data generator before stopping at the end of every epoch. It should typically be equal to the number of samples of your validation dataset divided by the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "steps_per_epoch = 8000,\n",
    "epochs = 25,\n",
    "#callbacks = acc_callback,\n",
    "validation_data = test_set,\n",
    "validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "* Load model from disk.\n",
    "* Preprocess and feed a random input image to the model for prediction.\n",
    "* Test the accuracy and loss using the evaluate_generator method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('saved_models/cnn_base_model.json', 'r')\n",
    "\n",
    "loaded_classifier_json = json_file.read()\n",
    "\n",
    "json_file.close()\n",
    "\n",
    "loaded_classifier = model_from_json(loaded_classifier_json)\n",
    "\n",
    "loaded_classifier.load_weights(\"saved_models/cnn_base_model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loaded_classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'This is a dog'\n",
    "else:\n",
    "    prediction = 'This is a cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = loaded_classifier.evaluate_generator(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization tools\n",
    "* plot_model : The keras.utils.vis_utils module provides utility functions to plot a Keras model (using graphviz).This will plot a graph of the model and save it to a file.\n",
    "* quiver_engine : Interactive deep convolutional networks features visualization.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(classifier, to_file='classifier.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quiver_engine import server\n",
    "server.launch(loaded_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
